version: '3.8'

x-spark-work: &spark-work
  build:
    context: .
    dockerfile: Dockerfile.spark
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
  command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  depends_on:
    - spark-master
  environment:
    SPARK_MODE: worker
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 1g
    SPARK_MASTER_URL: spark://spark-master:7077
    HADOOP_USER_NAME: spark
    HADOOP_CONF_DIR: ""
    HADOOP_SECURITY_AUTHENTICATION: simple
    HADOOP_SECURITY_AUTHORIZATION: false
    JAVA_SECURITY_KRB5_CONF: ""
  networks:
    - app-tier

services:
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      KAFKA_ENABLE_KRAFT:               "yes"
      KAFKA_CFG_PROCESS_ROLES:          "controller,broker"
      KAFKA_CFG_NODE_ID:                "1"
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS:  "1@kafka:9093"

      ALLOW_PLAINTEXT_LISTENER:         "yes"
      KAFKA_CFG_LISTENERS:              "PLAINTEXT://:9092,CONTROLLER://:9093"
      KAFKA_CFG_ADVERTISED_LISTENERS:   "PLAINTEXT://localhost:9092"
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
    ports:
      - "9092:9092"
      - "9093:9093"
    volumes:
      - kafka_data:/bitnami/kafka
    networks:
      - app-tier

  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs
      - ./jobs/spark-env.sh:/opt/bitnami/spark/conf/spark-env.sh
    command: bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      HADOOP_USER_NAME: spark
      HADOOP_CONF_DIR: ""
      HADOOP_SECURITY_AUTHENTICATION: simple
      HADOOP_SECURITY_AUTHORIZATION: false
      JAVA_SECURITY_KRB5_CONF: ""
    ports:
      - "9090:8080"
      - "7077:7077"
    networks:
      - app-tier
  spark-worker-1:
    <<: *spark-work

  spark-worker-2:
    <<: *spark-work

networks:
  app-tier:
volumes:
  kafka_data:
